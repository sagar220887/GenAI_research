# GenAI_research
POC on implementations and new features


## LLM Evaluation
 - Quantitative Performance metrics
 - Qualitative performance metrics

### How to build framework to evaluate LLM
 - 1. Model size and complexity
 - 2. Quality of training data and Diversity
 - 3. Bias and Fairness
 - 4. Ethical considerations
 - 5. Fine Tuning abd transfer Learning
 - 6. Explainability and Tracebility 
 - 7. Robustness and Adversarial attacks
 - 8. Continuous Monitoring and Improvement


### Evaluation Methods
 - 1. Embedding based
    a. BERT score
    b. Mover score
    c. WEAT
 - 2. LLM assisted evaluation
    a. RAGAS
    b. Arize AI
    c. GPT score
 - 3. Language based
    a. NLI score
    b. BLEURT
    c. QAQG score
 - 4. word based
    a. ROGUE
    b. BLEU
    c. WER
    d. METEOR
 - 5. Character Based
    a. Edit Distance



