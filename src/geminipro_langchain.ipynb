{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q google-generativeai langchain-google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] =GOOGLE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='models/gemini-pro',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name = \"gemini-pro\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Mixture of Experts (MoE)**\\n\\n**Definition:**\\n\\nMixture of Experts is a machine learning model that combines multiple expert models to make predictions. Each expert model specializes in a specific sub-domain or aspect of the problem.\\n\\n**How it Works:**\\n\\n1. **Input:** An input sample is presented to the MoE model.\\n2. **Gating Network:** A gating network (e.g., a neural network) calculates weights for each expert model based on the input sample. The weights represent the probability that each expert is suitable to handle the sample.\\n3. **Expert Models:** The gated input is passed to each expert model, which generates its own predictions.\\n4. **Weighted Sum:** The predictions from the expert models are then combined using a weighted sum based on the gating network's weights.\\n5. **Output:** The weighted sum is the final prediction of the MoE model.\\n\\n**Advantages:**\\n\\n* **Improved Performance:** By combining multiple experts, MoE models can capture complex relationships and improve prediction accuracy.\\n* **Modularity:** Expert models can be added or removed without affecting the overall structure of the MoE.\\n* **Scalability:** MoE models can be parallelized, making them suitable for large datasets and complex problems.\\n\\n**Disadvantages:**\\n\\n* **Increased Complexity:** MoE models can be computationally expensive to train and deploy due to the multiple expert models.\\n* **Overfitting:** The gating network can assign too much weight to specific experts, leading to overfitting.\\n* **Interpretability:** Understanding the contributions of different experts to the final decision can be challenging.\\n\\n**Applications:**\\n\\nMoE models have been successfully applied to various tasks, including:\\n\\n* Image classification\\n* Natural language processing\\n* Speech recognition\\n* Recommendation systems\\n\\n**Example:**\\n\\nConsider a MoE model for handwritten digit classification. The gating network could assign weights to expert models specializing in different types of digits (e.g., straight lines, curves). The expert models then make their predictions, and the weighted sum of these predictions is the final digit classification.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = [\n",
    "    \"What is Mixture of Experts?\",\n",
    "]\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is Mixture of Experts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Mixture of Experts (MoE)**\n",
      "\n",
      "**Definition:**\n",
      "\n",
      "Mixture of Experts is a machine learning model that consists of multiple specialized \"experts\" that are combined to provide a final prediction. Each expert is responsible for a specific sub-domain or task within the input space.\n",
      "\n",
      "**Concept:**\n",
      "\n",
      "* The input data is divided into multiple sub-domains, each handled by a different expert.\n",
      "* Each expert is trained on a subset of the data relevant to its sub-domain.\n",
      "* During prediction, the input is assigned to the expert that best matches its sub-domain.\n",
      "* The predictions from all experts are combined to produce the final output.\n",
      "\n",
      "**Advantages:**\n",
      "\n",
      "* **Improved Accuracy:** Experts can specialize in specific sub-domains, leading to better performance on complex tasks.\n",
      "* **Interpretability:** By examining the predictions of each expert, we can understand the model's reasoning and identify areas for improvement.\n",
      "* **Scalability:** MoE models can be scaled up to handle large datasets by adding more experts.\n",
      "\n",
      "**Disadvantages:**\n",
      "\n",
      "* **Increased Computational Cost:** Training and inference for MoE models can be more computationally expensive due to the multiple experts.\n",
      "* **Potential Overfitting:** If the experts are not well-trained, they can overfit to their respective sub-domains and make poor predictions.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "MoE models are used in a wide range of applications, including:\n",
      "\n",
      "* Natural Language Processing (NLP)\n",
      "* Computer Vision\n",
      "* Speech Recognition\n",
      "* Recommendation Systems\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Consider an image classification task. We can use a MoE model with the following experts:\n",
      "\n",
      "* Expert 1: Specialized in classifying animals\n",
      "* Expert 2: Specialized in classifying vehicles\n",
      "* Expert 3: Specialized in classifying plants\n",
      "\n",
      "When a new image is presented, the model assigns it to the most appropriate expert based on its features. The experts make their predictions, and the final classification is obtained by combining their results.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain + Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' A snow-capped mountain at sunset.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-27fe0750-b51b-4cc9-ad5e-9b661caec456-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "# example\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What's in this image?\",\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"image_url\", \n",
    "            \"image_url\": \"https://picsum.photos/seed/picsum/200/300\"\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: How to show an image from a given url within markdown\n",
    "\n",
    "# import requests\n",
    "# import io\n",
    "# from PIL import Image\n",
    "\n",
    "# def show_image(url):\n",
    "#   response = requests.get(url)\n",
    "#   image = Image.open(io.BytesIO(response.content))\n",
    "#   display(image)\n",
    "\n",
    "# show_image(\"https://tinyurl.com/xpb6vjdc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=' A snow-capped mountain peak.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-dcc8628d-b80f-402c-b966-023eca131342-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# picture description\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "# example\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What do you see in this image?\",\n",
    "        },\n",
    "        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/150\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = llm.invoke([message])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A mountain peak covered in snow.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The mountain stood tall and proud, its peak reaching up to the heavens. It was a symbol of strength and resilience, and it had stood there for centuries. The mountain had seen many things in its time. It had seen the rise and fall of civilizations, the coming and going of wars, and the birth and death of countless people. But through it all, the mountain had remained unchanged. It was a constant in a world of change.\n",
      "\n",
      "One day, a young man came to the mountain. He was a climber, and he had come to conquer the mountain. The young man was determined to reach the summit, and he was not going to let anything stop him. He began his climb, and he quickly made his way up the mountain. But as he got higher and higher, the climb became more and more difficult. The air became thinner, and the wind became stronger. The young man was starting to get tired, but he kept going. He was determined to reach the summit.\n",
      "\n",
      "Finally, after hours of climbing, the young man reached the summit of the mountain. He was exhausted, but he was also exhilarated. He had achieved his goal, and he had proven to himself that he could do anything he set his mind to. The young man stood at the summit of the mountain and looked out at the world below. He felt a sense of peace and tranquility. He knew that he would never forget this moment.\n",
      "\n",
      "The young man's story is a reminder that anything is possible if you set your mind to it. No matter how difficult the challenge, if you keep going, you will eventually achieve your goal. So never give up on your dreams. Keep climbing, and you will eventually reach the summit.\n"
     ]
    }
   ],
   "source": [
    "## short story content\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro-vision\")\n",
    "# example\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"What do you see in this image? Create a short story based on the content\",\n",
    "        },\n",
    "        {\"type\": \"image_url\", \"image_url\": \"https://picsum.photos/seed/picsum/200/150\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = llm.invoke([message])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
