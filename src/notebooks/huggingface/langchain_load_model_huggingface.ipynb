{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-huggingface huggingface_hub transformers accelerate bitsandbytes langchain -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\LENOVO\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=HUGGINGFACEHUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? Machine learning is a type of artificial intelligence (AI) that allows systems to learn from and make decisions based on data. In machine learning, algorithms are used to identify patterns and make decisions with minimal human intervention. This approach to AI is becoming increasingly popular due to its ability to analyze large amounts of data and make accurate predictions and decisions.\\n\\nMachine learning algorithms can be broadly classified into three categories: supervised learning, unsupervised learning, and reinforcement learning.\\n\\n1. Supervised learning: In supervised learning, the algorithm is trained on labeled data, meaning that the data includes both the input and the correct output. The algorithm learns to map inputs to outputs by finding the relationship between them. For example, a supervised learning algorithm could be used to identify email spam based on labeled data, where each email is labeled as either spam or not spam.\\n2. Unsupervised learning: In unsupervised learning, the algorithm is trained on unlabeled data, meaning that there is no correct output provided. The algorithm must find patterns and relationships in the data on its own. For example, an unsupervised learning algorithm could be used to identify clusters of customers based on their purchasing behavior.\\n3. Reinforcement learning: In reinforcement learning, the algorithm learns by interacting with its environment and receiving feedback in the form of rewards or penalties. The algorithm learns to take actions that maximize rewards and minimize penalties. For example, a reinforcement learning algorithm could be used to teach a robot to navigate a maze and collect rewards.\\n\\nMachine learning is used in a variety of applications, including image and speech recognition, natural language processing, fraud detection, recommendation systems, and predictive maintenance. It is also being used to develop autonomous vehicles and drones, and to improve healthcare diagnosis and treatment.\\n\\nMachine learning algorithms are trained on large amounts of data using powerful computers and specialized hardware, such as GPUs (graphics processing units) and TPUs (tensor processing units). Once trained, the algorithms can be deployed in a variety of environments, including on-premises servers, cloud services, and edge devices.\\n\\nMachine learning is a rapidly evolving field, with new algorithms and applications being developed all the time. It is an exciting area of research and development, with the potential to transform the way we live and work.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\LENOVO\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=HUGGINGFACEHUB_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nGenerative AI refers to a type of artificial intelligence (AI) that can create new content, such as images, text, or music, based on patterns and data it has been trained on. It uses machine learning algorithms to generate outputs that are similar to, but not identical to, the data it was trained on.\\n\\nGenerative AI models can be used in various applications, such as:\\n\\n1. Content creation: Generative AI can create text, images, and music that resemble human-made content. For example, it can be used to generate news articles, write poems, or compose music.\\n2. Personalization: Generative AI can be used to create personalized content for users, such as customized product recommendations or personalized chatbot responses.\\n3. Design: Generative AI can be used to create designs for various applications, such as fashion, architecture, or product design.\\n4. Data augmentation: Generative AI can be used to generate synthetic data to augment training datasets, which can improve the accuracy and performance of other AI models.\\n\\nGenerative AI models are typically trained on large datasets and use techniques such as deep learning, generative adversarial networks (GANs), or variational autoencoders (VAEs) to generate new content. These models can be complex and require significant computational resources to train and run.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "llm.invoke(\"What is Genertaive AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Who won the Cricket World Cup in the year 2011?', 'text': \" The Cricket World Cup is a tournament held every four years. The year 2011 is indeed a year that falls within a World Cup cycle. To determine the winner, we would need to look up the results of the 2011 Cricket World Cup.\\n\\nThe 2011 Cricket World Cup was won by India, who defeated Sri Lanka in the final match. India won the championship by six wickets with 10 balls remaining. This victory marked India's second Cricket World Cup title, with their first win being in 1983.\\n\\nSo, the answer is India won the Cricket World Cup in 2011.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "question=\"Who won the Cricket World Cup in the year 2011?\"\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "# print(prompt)\n",
    "\n",
    "\n",
    "\n",
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "model_id=\"gpt2\"\n",
    "model=AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
    "config=AutoConfig.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./models/gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "\n",
    "tokenizer.save_pretrained(\"./models/tokenizer/\")\n",
    "config.save_pretrained('./models/tokenizer')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./models/tokenizer')\n",
    "# tokenizer2 = DistilBertTokenizer.from_pretrained(\"./models/tokenizer/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_loaded = AutoTokenizer.from_pretrained('./models/tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ./models/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model_loaded = AutoModelForSequenceClassification.from_pretrained(\"./models/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe=pipeline(\"text-generation\",model=model,tokenizer=tokenizer_loaded,max_new_tokens=100)\n",
    "hf=HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"What is machine learning?\\n\\nIn machine learning we're talking about machine learning which uses machines learning to teach or teach how to solve a mathematical problem. To do that, we must learn by means of an artificial neural network (AI) â€“ that is, using an iterative learning algorithm to build artificial models of the underlying problem.\\n\\nOnce we have an algorithm build to solve a problem, then we are able to use AI as a way to identify the underlying problems. For instance, the problem is about how\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hf.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
