{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ce9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers\n",
    "import os\n",
    "from pathlib import Path\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4ad02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = Path(os.path.join(os.getcwd(), os.pardir)).parent.parent\n",
    "user_query = \"what is Applied Generative AI for Beginners?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cabe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unterscheidung between Generative and Discriminative Models.\n",
      "Generative models are a class of machine learning algorithms that can generate new data samples that are similar to the training data. These models learn the underlying distribution of the input data and can produce realistic synthetic examples. In contrast, discriminative models are trained to predict a target variable based on input features. They focus on identifying patterns in the input data rather than generating new data.\n",
      "Generative models can be further divided into two categories: generative adversarial networks (GANs) and variational autoencoders (VAEs). GANs consist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "src_dir = parent_dir.parent\n",
    "\n",
    "model_dir = os.path.join(src_dir, 'model')\n",
    "model_path=os.path.join(model_dir, 'llama-2-7b-chat.ggmlv3.q4_0.bin')\n",
    "\n",
    "llm=CTransformers(\n",
    "        model=model_path,\n",
    "        model_type=\"llama\",\n",
    "        config={'max_new_tokens':128,\n",
    "                'temperature':0.01,\n",
    "                'context_length': 200\n",
    "                }\n",
    ")\n",
    "\n",
    "\n",
    "# print(llm.invoke(user_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b2c92",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac65dd2",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb4f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pdf_file_path = os.path.join(parent_dir, 'data', 'Applied Generative AI for Beginners.pdf')\n",
    "\n",
    "loader = PyPDFLoader(pdf_file_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff1eaa",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c040b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents length -  435\n"
     ]
    }
   ],
   "source": [
    "recursive_char_text_splitter=RecursiveCharacterTextSplitter(\n",
    "                                                chunk_size=1000,\n",
    "                                                chunk_overlap=50)\n",
    "documents=recursive_char_text_splitter.split_documents(data)\n",
    "print('documents length - ', len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6295e",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81f829e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "embedding_path = os.path.join(parent_dir, 'model', 'embeddings')\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2', \n",
    "    model_kwargs={'device':'cpu'},\n",
    "    cache_folder=embedding_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29beacae",
   "metadata": {},
   "source": [
    "### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8121021",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_directory = os.path.join(parent_dir, 'model', 'vectorDB')\n",
    "new_knowledge_base =FAISS.from_documents(documents, embeddings)\n",
    "new_knowledge_base.save_local(vector_db_directory)\n",
    "\n",
    "\n",
    "loaded_vector_db = FAISS.load_local(vector_db_directory, embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8717ac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='So, What Is Generative AI?\\nGenerative AI  refers to a branch of artificial intelligence  that focuses on\\ncreating models and algorithms  capable of generating new , original content,\\nsuch as images, text, music, and even videos. Unlike traditional AI models\\nthat are trained to perform specific tasks, generative AI models aim to learn\\nand mimic patterns from existing data to generate new , unique outputs.\\nGenerative AI has a wide range of applications. For instance, in\\ncomputer vision, generative models can generate realistic images, create\\nvariations of existing images, or even complete missing parts of an image.\\nIn natural language processing, generative models can be used for language\\ntranslation, text synthesis, or even to create conversational agents that\\nproduce humanlike responses. Beyond these examples, generative ai can\\nperform art generation, data augmentation, and even generating synthetic\\nmedical images for research and diagnosis. It’ s a powerful and creative tool', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 20}),\n",
       " Document(page_content='Deep Learning (DL): A specialized subset of ML, deep learning involves\\nneural networks with three or more layers that can analyze various\\nfactors of a dataset.\\nGenerative AI: An advanced subset of AI and DL, generative AI focuses\\non creating new and unique outputs. It goes beyond the scope of simply\\nanalyzing data to making new creations based on learned patterns.\\nFigure 1-2 explains how generative AI is a component of AI.\\nFigure 1-2  AI and its components\\nDomains of Generative AI\\nLet’s deep dive into domains of generative AI in detail, including what it is,\\nhow it works, and some practical applications.', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 21}),\n",
       " Document(page_content='Introduction\\nWelcome to Applied Generative AI for Beginners: Practical Knowledge on\\nDiffusion Models, ChatGPT , and Other LLMs . Within these pages, you’re\\nabout to embark on an exhilarating journey into the world of generative\\nartificial intelligence (AI). This book serves as a comprehensive guide that\\nnot only unveils the intricacies of generative AI but also equips you with\\nthe knowledge and skills to implement it.\\nIn recent years, generative AI has emer ged as a powerhouse of\\ninnovation, reshaping the technological landscape and redefining the\\nboundaries of what machines can achieve. At its core, generative AI\\nempowers artificial systems to understand and generate human language\\nwith remarkable fluency and creativity . As we delve deep into this\\ncaptivating landscape, you’ll gain both a theoretical foundation and\\npractical insights into this cutting-edge field.\\nWhat Y ou W ill Discover\\nThroughout the chapters of this book, you will', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 5}),\n",
       " Document(page_content='Akshay\\xa0Kulkarni , Adarsha\\xa0Shivananda , Anoosh\\xa0Kulkarni  and\\nDilip\\xa0Gudivada\\nApplied Generative AI for Beginners\\nPractical Knowledge on Diffusion Models, ChatGPT , and\\nOther LLMs', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = loaded_vector_db.as_retriever()\n",
    "retriever.get_relevant_documents(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbcc183",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7525cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3208e",
   "metadata": {},
   "source": [
    "### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f9daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type='stuff',\n",
    "            retriever=loaded_vector_db.as_retriever(search_kwargs={'k': 4}),\n",
    "            return_source_documents=True,\n",
    "            chain_type_kwargs={'prompt': prompt}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9610504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\sagar\\work\\AI_ML\\gitrepo\\GENAI\\YOUTUBES\\GenAI_research\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Number of tokens (747) exceeded maximum context length (200).\n",
      "Number of tokens (748) exceeded maximum context length (200).\n",
      "Number of tokens (749) exceeded maximum context length (200).\n",
      "Number of tokens (750) exceeded maximum context length (200).\n",
      "Number of tokens (751) exceeded maximum context length (200).\n",
      "Number of tokens (752) exceeded maximum context length (200).\n",
      "Number of tokens (753) exceeded maximum context length (200).\n",
      "Number of tokens (754) exceeded maximum context length (200).\n",
      "Number of tokens (755) exceeded maximum context length (200).\n",
      "Number of tokens (756) exceeded maximum context length (200).\n",
      "Number of tokens (757) exceeded maximum context length (200).\n",
      "Number of tokens (758) exceeded maximum context length (200).\n",
      "Number of tokens (759) exceeded maximum context length (200).\n",
      "Number of tokens (760) exceeded maximum context length (200).\n",
      "Number of tokens (761) exceeded maximum context length (200).\n",
      "Number of tokens (762) exceeded maximum context length (200).\n",
      "Number of tokens (763) exceeded maximum context length (200).\n",
      "Number of tokens (764) exceeded maximum context length (200).\n",
      "Number of tokens (765) exceeded maximum context length (200).\n",
      "Number of tokens (766) exceeded maximum context length (200).\n",
      "Number of tokens (767) exceeded maximum context length (200).\n",
      "Number of tokens (768) exceeded maximum context length (200).\n",
      "Number of tokens (769) exceeded maximum context length (200).\n",
      "Number of tokens (770) exceeded maximum context length (200).\n",
      "Number of tokens (771) exceeded maximum context length (200).\n",
      "Number of tokens (772) exceeded maximum context length (200).\n",
      "Number of tokens (773) exceeded maximum context length (200).\n",
      "Number of tokens (774) exceeded maximum context length (200).\n",
      "Number of tokens (775) exceeded maximum context length (200).\n",
      "Number of tokens (776) exceeded maximum context length (200).\n",
      "Number of tokens (777) exceeded maximum context length (200).\n",
      "Number of tokens (778) exceeded maximum context length (200).\n",
      "Number of tokens (779) exceeded maximum context length (200).\n",
      "Number of tokens (780) exceeded maximum context length (200).\n",
      "Number of tokens (781) exceeded maximum context length (200).\n",
      "Number of tokens (782) exceeded maximum context length (200).\n",
      "Number of tokens (783) exceeded maximum context length (200).\n",
      "Number of tokens (784) exceeded maximum context length (200).\n",
      "Number of tokens (785) exceeded maximum context length (200).\n",
      "Number of tokens (786) exceeded maximum context length (200).\n",
      "Number of tokens (787) exceeded maximum context length (200).\n",
      "Number of tokens (788) exceeded maximum context length (200).\n",
      "Number of tokens (789) exceeded maximum context length (200).\n",
      "Number of tokens (790) exceeded maximum context length (200).\n",
      "Number of tokens (791) exceeded maximum context length (200).\n",
      "Number of tokens (792) exceeded maximum context length (200).\n",
      "Number of tokens (793) exceeded maximum context length (200).\n",
      "Number of tokens (794) exceeded maximum context length (200).\n",
      "Number of tokens (795) exceeded maximum context length (200).\n",
      "Number of tokens (796) exceeded maximum context length (200).\n",
      "Number of tokens (797) exceeded maximum context length (200).\n",
      "Number of tokens (798) exceeded maximum context length (200).\n",
      "Number of tokens (799) exceeded maximum context length (200).\n",
      "Number of tokens (800) exceeded maximum context length (200).\n",
      "Number of tokens (801) exceeded maximum context length (200).\n",
      "Number of tokens (802) exceeded maximum context length (200).\n",
      "Number of tokens (803) exceeded maximum context length (200).\n",
      "Number of tokens (804) exceeded maximum context length (200).\n",
      "Number of tokens (805) exceeded maximum context length (200).\n",
      "Number of tokens (806) exceeded maximum context length (200).\n",
      "Number of tokens (807) exceeded maximum context length (200).\n",
      "Number of tokens (808) exceeded maximum context length (200).\n",
      "Number of tokens (809) exceeded maximum context length (200).\n",
      "Number of tokens (810) exceeded maximum context length (200).\n",
      "Number of tokens (811) exceeded maximum context length (200).\n",
      "Number of tokens (812) exceeded maximum context length (200).\n",
      "Number of tokens (813) exceeded maximum context length (200).\n",
      "Number of tokens (814) exceeded maximum context length (200).\n",
      "Number of tokens (815) exceeded maximum context length (200).\n",
      "Number of tokens (816) exceeded maximum context length (200).\n",
      "Number of tokens (817) exceeded maximum context length (200).\n",
      "Number of tokens (818) exceeded maximum context length (200).\n",
      "Number of tokens (819) exceeded maximum context length (200).\n",
      "Number of tokens (820) exceeded maximum context length (200).\n",
      "Number of tokens (821) exceeded maximum context length (200).\n",
      "Number of tokens (822) exceeded maximum context length (200).\n",
      "Number of tokens (823) exceeded maximum context length (200).\n",
      "Number of tokens (824) exceeded maximum context length (200).\n",
      "Number of tokens (825) exceeded maximum context length (200).\n",
      "Number of tokens (826) exceeded maximum context length (200).\n",
      "Number of tokens (827) exceeded maximum context length (200).\n",
      "Number of tokens (828) exceeded maximum context length (200).\n",
      "Number of tokens (829) exceeded maximum context length (200).\n",
      "Number of tokens (830) exceeded maximum context length (200).\n",
      "Number of tokens (831) exceeded maximum context length (200).\n",
      "Number of tokens (832) exceeded maximum context length (200).\n",
      "Number of tokens (833) exceeded maximum context length (200).\n",
      "Number of tokens (834) exceeded maximum context length (200).\n",
      "Number of tokens (835) exceeded maximum context length (200).\n",
      "Number of tokens (836) exceeded maximum context length (200).\n",
      "Number of tokens (837) exceeded maximum context length (200).\n",
      "Number of tokens (838) exceeded maximum context length (200).\n",
      "Number of tokens (839) exceeded maximum context length (200).\n",
      "Number of tokens (840) exceeded maximum context length (200).\n",
      "Number of tokens (841) exceeded maximum context length (200).\n",
      "Number of tokens (842) exceeded maximum context length (200).\n",
      "Number of tokens (843) exceeded maximum context length (200).\n",
      "Number of tokens (844) exceeded maximum context length (200).\n",
      "Number of tokens (845) exceeded maximum context length (200).\n",
      "Number of tokens (846) exceeded maximum context length (200).\n",
      "Number of tokens (847) exceeded maximum context length (200).\n",
      "Number of tokens (848) exceeded maximum context length (200).\n",
      "Number of tokens (849) exceeded maximum context length (200).\n",
      "Number of tokens (850) exceeded maximum context length (200).\n",
      "Number of tokens (851) exceeded maximum context length (200).\n",
      "Number of tokens (852) exceeded maximum context length (200).\n",
      "Number of tokens (853) exceeded maximum context length (200).\n",
      "Number of tokens (854) exceeded maximum context length (200).\n",
      "Number of tokens (855) exceeded maximum context length (200).\n",
      "Number of tokens (856) exceeded maximum context length (200).\n",
      "Number of tokens (857) exceeded maximum context length (200).\n",
      "Number of tokens (858) exceeded maximum context length (200).\n",
      "Number of tokens (859) exceeded maximum context length (200).\n",
      "Number of tokens (860) exceeded maximum context length (200).\n",
      "Number of tokens (861) exceeded maximum context length (200).\n",
      "Number of tokens (862) exceeded maximum context length (200).\n",
      "Number of tokens (863) exceeded maximum context length (200).\n",
      "Number of tokens (864) exceeded maximum context length (200).\n",
      "Number of tokens (865) exceeded maximum context length (200).\n",
      "Number of tokens (866) exceeded maximum context length (200).\n",
      "Number of tokens (867) exceeded maximum context length (200).\n",
      "Number of tokens (868) exceeded maximum context length (200).\n",
      "Number of tokens (869) exceeded maximum context length (200).\n",
      "Number of tokens (870) exceeded maximum context length (200).\n",
      "Number of tokens (871) exceeded maximum context length (200).\n",
      "Number of tokens (872) exceeded maximum context length (200).\n",
      "Number of tokens (873) exceeded maximum context length (200).\n",
      "Number of tokens (874) exceeded maximum context length (200).\n",
      "Number of tokens (875) exceeded maximum context length (200).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result -  {'result': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 'source_documents': [Document(page_content='So, What Is Generative AI?\\nGenerative AI  refers to a branch of artificial intelligence  that focuses on\\ncreating models and algorithms  capable of generating new , original content,\\nsuch as images, text, music, and even videos. Unlike traditional AI models\\nthat are trained to perform specific tasks, generative AI models aim to learn\\nand mimic patterns from existing data to generate new , unique outputs.\\nGenerative AI has a wide range of applications. For instance, in\\ncomputer vision, generative models can generate realistic images, create\\nvariations of existing images, or even complete missing parts of an image.\\nIn natural language processing, generative models can be used for language\\ntranslation, text synthesis, or even to create conversational agents that\\nproduce humanlike responses. Beyond these examples, generative ai can\\nperform art generation, data augmentation, and even generating synthetic\\nmedical images for research and diagnosis. It’ s a powerful and creative tool', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 20}), Document(page_content='Deep Learning (DL): A specialized subset of ML, deep learning involves\\nneural networks with three or more layers that can analyze various\\nfactors of a dataset.\\nGenerative AI: An advanced subset of AI and DL, generative AI focuses\\non creating new and unique outputs. It goes beyond the scope of simply\\nanalyzing data to making new creations based on learned patterns.\\nFigure 1-2 explains how generative AI is a component of AI.\\nFigure 1-2  AI and its components\\nDomains of Generative AI\\nLet’s deep dive into domains of generative AI in detail, including what it is,\\nhow it works, and some practical applications.', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 21}), Document(page_content='Introduction\\nWelcome to Applied Generative AI for Beginners: Practical Knowledge on\\nDiffusion Models, ChatGPT , and Other LLMs . Within these pages, you’re\\nabout to embark on an exhilarating journey into the world of generative\\nartificial intelligence (AI). This book serves as a comprehensive guide that\\nnot only unveils the intricacies of generative AI but also equips you with\\nthe knowledge and skills to implement it.\\nIn recent years, generative AI has emer ged as a powerhouse of\\ninnovation, reshaping the technological landscape and redefining the\\nboundaries of what machines can achieve. At its core, generative AI\\nempowers artificial systems to understand and generate human language\\nwith remarkable fluency and creativity . As we delve deep into this\\ncaptivating landscape, you’ll gain both a theoretical foundation and\\npractical insights into this cutting-edge field.\\nWhat Y ou W ill Discover\\nThroughout the chapters of this book, you will', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 5}), Document(page_content='Akshay\\xa0Kulkarni , Adarsha\\xa0Shivananda , Anoosh\\xa0Kulkarni  and\\nDilip\\xa0Gudivada\\nApplied Generative AI for Beginners\\nPractical Knowledge on Diffusion Models, ChatGPT , and\\nOther LLMs', metadata={'source': 'c:\\\\Users\\\\LENOVO\\\\sagar\\\\work\\\\AI_ML\\\\gitrepo\\\\GENAI\\\\YOUTUBES\\\\GenAI_research\\\\src\\\\data\\\\Applied Generative AI for Beginners.pdf', 'page': 1})]}\n",
      "Answer:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chain({'query':user_query}, return_only_outputs=True)\n",
    "print('result - ', result)\n",
    "ans = result['result']\n",
    "print(f\"Answer:{ans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f5039a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6539ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1e677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ae4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
